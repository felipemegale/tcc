{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d246aa5-0424-4a94-94f0-68d28e5e5dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pyspark to process large files\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, asc, desc, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8e88d40-5ee4-42fa-94e8-b6639ca555e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "# create a new spark session\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[*]')\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .appName('process_tripdata')\\\n",
    "    .getOrCreate()\n",
    "print(\"Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d96e907-e5c8-4414-a5d2-173dc2e8787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 2019-01 data\n",
    "jan_data = spark\\\n",
    "    .read\\\n",
    "    .csv('/media/felipe/Files/repos/tcc/nyc_data/csv/2019/01/fhv_tripdata_2019-01.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb83ffa-e341-4193-abc4-d25bbb88577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B00001|2019-01-01 00:30:00|2019-01-01 02:51:55|        null|        null|   null|\n",
      "|              B00001|2019-01-01 00:45:00|2019-01-01 00:54:49|        null|        null|   null|\n",
      "|              B00001|2019-01-01 00:15:00|2019-01-01 00:54:52|        null|        null|   null|\n",
      "|              B00008|2019-01-01 00:19:00|2019-01-01 00:39:00|        null|        null|   null|\n",
      "|              B00008|2019-01-01 00:27:00|2019-01-01 00:37:00|        null|        null|   null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show jan_data head\n",
    "jan_data.printSchema()\n",
    "jan_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acef4643-fc0f-4435-901f-53102f1ca173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23130810\n"
     ]
    }
   ],
   "source": [
    "# get jan data count -> 23,130,810\n",
    "# print(jan_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "870d42a6-841d-404d-9825-b917cb5e2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B00254|2019-01-01 00:33:03|2019-01-01 01:37:24|         140|          52|   null|\n",
      "|              B00254|2019-01-01 00:03:00|2019-01-01 00:34:25|         141|         237|   null|\n",
      "|              B00254|2019-01-01 00:45:48|2019-01-01 01:26:01|         237|         236|   null|\n",
      "|              B00254|2019-01-01 00:37:39|2019-01-01 01:44:59|         162|          85|   null|\n",
      "|              B00254|2019-01-01 00:35:06|2019-01-01 01:30:21|         237|         246|   null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter off null PU and DO location IDs\n",
    "jan_data.createOrReplaceTempView(\"JAN_DATA_TEMP_VIEW\")\n",
    "jan_data = spark.sql(\"SELECT * FROM JAN_DATA_TEMP_VIEW WHERE PULocationID IS NOT NULL AND DOLocationID IS NOT NULL\")\n",
    "jan_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c385f0f7-14d0-436b-955a-8b2c39ee59d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21306221\n"
     ]
    }
   ],
   "source": [
    "# get jan data count after filtering -> 21,306,221\n",
    "# print(jan_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84312522-43f5-4e4d-bb8e-d10651f14999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PU and DO location ID cols to int\n",
    "jan_data = jan_data.withColumn(\"PULocationID\", jan_data.PULocationID.cast('int'))\n",
    "jan_data = jan_data.withColumn(\"DOLocationID\", jan_data.DOLocationID.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ba221f-b849-4e09-8117-e1f46fc9dbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dispatching_base_num: string, pickup_datetime: string, dropoff_datetime: string, PULocationID: int, DOLocationID: int, SR_Flag: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view jan_data schema after casting PU and DO cols to int\n",
    "jan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5349be45-8c0c-49f2-b0cf-45ad117ce318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load taxi zones\n",
    "taxi_zones = spark.read.csv('/media/felipe/Files/repos/tcc/nyc_data/csv/taxi_zone_lookup.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9deffed9-f481-4190-93e0-0969a384a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show taxi_zones head\n",
    "taxi_zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "948bec43-b25b-4ca4-bed9-e0205df06f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get how many trips departured from or went to unknown zones\n",
    "jan_data = jan_data.where(\"PULocationID < 264 AND DOLocationID < 264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e3cb2e-247d-46f4-b3ce-745c292a2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19847478\n"
     ]
    }
   ],
   "source": [
    "# count how many trips did not depart or arrive to unknown zones -> 19,847,478\n",
    "# print(jan_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e35f01ed-8914-42dc-a4ad-b85677705983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where PU and DO cols are 0\n",
    "jan_data.createOrReplaceTempView(\"JAN_DATA_TEMP_VIEW\")\n",
    "jan_data = spark.sql(\"SELECT * FROM JAN_DATA_TEMP_VIEW WHERE PULocationID <> 0 AND DOLocationID <> 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04fe9bcc-5018-4169-b80c-0bccf0037603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19847263\n"
     ]
    }
   ],
   "source": [
    "# count how many trips PU and DO locations are 0 -> 19,847,263\n",
    "# print(jan_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860ce041-1a8d-420f-ad97-78c577c7b111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(MAX_PU=263, MAX_DO=263)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get greatest PU and DO location ID to begin assembly of OD dataframe\n",
    "# jan_data.createOrReplaceTempView(\"JAN_DATA_TEMP_VIEW\")\n",
    "# spark.sql(\"SELECT MAX(PULocationID) AS MAX_PU, MAX(DOLocationID) AS MAX_DO FROM JAN_DATA_TEMP_VIEW\")\\\n",
    "#     .first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142588c3-7228-4d59-9c4e-f1b8f73b7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin OD matrix dataframe assembly\n",
    "od_size = 264 # 263 + 1 to account for 0-index in list\n",
    "od_data = [[0 for x in range(od_size)] for y in range(od_size)]\n",
    "od_cols = [str(x) for x in range(od_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e85ab29-eda6-4f71-a050-53ca5fe5a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill january OD matrix dataframe\n",
    "jan_data_collect = jan_data.toLocalIterator()\n",
    "for row in jan_data_collect:\n",
    "    origin = row.PULocationID\n",
    "    destination = row.DOLocationID\n",
    "    od_data[origin][destination] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc61f9b5-9fa8-43ec-9307-6a86c83c4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create OD dataframe from OD matrix\n",
    "od_dataframe = spark.createDataFrame(data=od_data,schema=od_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fa419f-16dc-47c0-b222-e9c852790e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and populate list of max trips from to location\n",
    "od_dataframe_collect = od_dataframe.toLocalIterator()\n",
    "origin = 0\n",
    "od_greatest_values = []\n",
    "\n",
    "for row in od_dataframe_collect:\n",
    "    max_val = max(list(row))\n",
    "    destination = row.index(max_val)\n",
    "    od_greatest_values.append((origin, destination, max_val))\n",
    "    origin += 1\n",
    "\n",
    "# create dataframe from od_greatest_values list\n",
    "od_gr_df_cols = [\"PULocationID\", \"DOLocationID\", \"TripQty\"]\n",
    "od_gr_df = spark.createDataFrame(data=od_greatest_values, schema=od_gr_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8399338f-c7c9-4eb1-a407-1ddc1fb2efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------+\n",
      "|PULocationID|DOLocationID|TripQty|\n",
      "+------------+------------+-------+\n",
      "|           0|           0|      0|\n",
      "|           1|         231|     87|\n",
      "|           2|         117|      3|\n",
      "|           3|          51|   2598|\n",
      "|           4|          79|   4539|\n",
      "+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show od_gr_df head\n",
    "od_gr_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2af6ae-9114-462a-9d5a-b1ed64df8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------+\n",
      "|PULocationID|DOLocationID|TripQty|\n",
      "+------------+------------+-------+\n",
      "|          76|          76|  38431|\n",
      "|          26|          26|  33860|\n",
      "|          61|          61|  32658|\n",
      "|          39|          39|  29426|\n",
      "|           7|           7|  26702|\n",
      "|         181|         181|  26328|\n",
      "|         129|         129|  25298|\n",
      "|          14|          14|  23169|\n",
      "|          37|          37|  21124|\n",
      "|          36|          37|  19902|\n",
      "+------------+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# order by TripQty to find find the top destinations\n",
    "od_gr_df = od_gr_df.orderBy(col(\"TripQty\").desc())\n",
    "od_gr_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a576b826-f2ae-4c1c-9461-e98f0fe5c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract january top OD data\n",
    "jan_top_ods = od_gr_df.join(taxi_zones,od_gr_df.PULocationID == taxi_zones.LocationID, \"inner\")\\\n",
    "    .drop(\"Borough\", \"service_zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a42891-daa3-4659-b518-fa891fd5af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write to file or file already exists\n"
     ]
    }
   ],
   "source": [
    "# save january top ODs to file\n",
    "try:\n",
    "    jan_top_ods\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2019/01/top_ods.csv\")\n",
    "except:\n",
    "    print(\"Could not write top_ods to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ede82660-37a2-45dd-ad10-fae7c71715a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|    pickup_datetime|\n",
      "+-------------------+\n",
      "|2019-01-01 00:33:03|\n",
      "|2019-01-01 00:03:00|\n",
      "|2019-01-01 00:45:48|\n",
      "|2019-01-01 00:37:39|\n",
      "|2019-01-01 00:35:06|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up helper lists for trip division by time of day\n",
    "jan_pickup_times = jan_data.select(\"pickup_datetime\")\n",
    "jan_pickup_times = jan_pickup_times.withColumn(\"pickup_datetime\",to_timestamp(\"pickup_datetime\"))\n",
    "jan_pickup_times.printSchema()\n",
    "jan_pickup_times.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31ba1d94-6c47-454a-ae50-533a193fcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many trips per day period\n",
    "# morning: 0:00 to 5:59\n",
    "# day: 6:00 to 11:59\n",
    "# noon: 12:00 to 17:59\n",
    "# night: 18:00 to 23:59\n",
    "# weekday is 0-index starting monday (0), then tuesday (1), etc.\n",
    "\n",
    "MORNING=1\n",
    "DAY=2\n",
    "NOON=3\n",
    "NIGHT=4\n",
    "trip_groups_schema = ['day of week', 'morning', 'day', 'noon', 'night']\n",
    "trip_groups = [['mon', 0, 0, 0, 0],\\\n",
    "               ['tue', 0, 0, 0, 0],\\\n",
    "               ['wed', 0, 0, 0, 0],\\\n",
    "               ['thu', 0, 0, 0, 0],\\\n",
    "               ['fri', 0, 0, 0, 0],\\\n",
    "               ['sat', 0, 0, 0, 0],\\\n",
    "               ['sun', 0, 0, 0, 0]]\n",
    "\n",
    "jan_pickup_times_collect = jan_pickup_times.toLocalIterator()\n",
    "rows_with_issues = []\n",
    "\n",
    "for row in jan_pickup_times_collect:\n",
    "    trip_weekday = row.pickup_datetime.weekday()\n",
    "    trip_hour = row.pickup_datetime.hour\n",
    "    if 0 <= trip_hour <= 5:\n",
    "        trip_groups[trip_weekday][MORNING] += 1\n",
    "    elif 6 <= trip_hour <= 11:\n",
    "        trip_groups[trip_weekday][DAY] += 1\n",
    "    elif 12 <= trip_hour <= 17:\n",
    "        trip_groups[trip_weekday][NOON] += 1\n",
    "    elif 18 <= trip_hour <= 23:\n",
    "        trip_groups[trip_weekday][NIGHT] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf7bb15e-1284-4eab-a41e-52ba5872b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF from trip dow group matrix\n",
    "trip_dow_df = spark.createDataFrame(data=trip_groups, schema=trip_groups_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "928bb7e1-c9e6-4fbc-b140-d91dc76a892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+------+-------+\n",
      "|day of week|morning|   day|  noon|  night|\n",
      "+-----------+-------+------+------+-------+\n",
      "|        mon| 199734|660084|725648| 750663|\n",
      "|        tue| 460169|779835|827451| 942559|\n",
      "|        wed| 229950|821136|838730|1000248|\n",
      "|        thu| 249241|916219|934264|1106713|\n",
      "|        fri| 235848|679735|762618|1054765|\n",
      "|        sat| 479668|531886|892784|1138060|\n",
      "|        sun| 571719|464548|816346| 776642|\n",
      "+-----------+-------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show trip_dow_df\n",
    "trip_dow_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "977ce638-352e-4541-9e1a-a45306929ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write trip_dow_df to file\n",
    "try:\n",
    "    trip_dow_df\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2019/01/trip_dow_time.csv\")\n",
    "except:\n",
    "    print(\"Could not write trip_dow_time to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b56c94f-c479-49a0-885a-8f159b1be959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B02395|2019-01-01 00:50:26|2019-01-01 01:16:07|          48|         144|      1|\n",
      "|              B02395|2019-01-01 00:51:20|2019-01-01 01:16:07|          48|         144|      2|\n",
      "|              B02395|2019-01-01 00:56:24|2019-01-01 01:10:11|         181|          54|      1|\n",
      "|              B02395|2019-01-01 00:58:12|2019-01-01 01:02:23|         181|         181|      2|\n",
      "|              B02395|2019-01-01 00:24:44|2019-01-01 00:29:54|         126|         168|      1|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get trips that were shared\n",
    "jan_data.createOrReplaceTempView(\"JAN_DATA_TEMP_VIEW\")\n",
    "shared_trips = spark.sql(\"SELECT * FROM JAN_DATA_TEMP_VIEW WHERE SR_Flag IS NOT NULL\")\n",
    "shared_trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c636381-4cc3-45ac-aa33-c3dcdba9e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared jan trips 5361332\n"
     ]
    }
   ],
   "source": [
    "# count how many trips were shared -> 5,361,332\n",
    "\n",
    "# As per the documentation, there are trips that were flagged as shareable.\n",
    "# however, this does not mean that it was, since Lyft flags as shared even though\n",
    "# the original rider wasnt matched with someone else.\n",
    "# For the purposes of this study, we will analyze the users intent to share.\n",
    "\n",
    "print('shared jan trips', shared_trips.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01ad21-391c-45b5-a70c-c443217cf90f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f95c251-4b9f-45fe-9395-4594373fd15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:45:22 WARN Utils: Your hostname, LAPTOP-VD4O2HIL resolves to a loopback address: 127.0.1.1; using 172.30.165.94 instead (on interface eth0)\n",
      "21/11/24 13:45:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/11/24 13:45:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# import pyspark to process large files and create a new spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, asc, desc, to_timestamp, when\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[*]')\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .appName('process_tripdata')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768a4d62-4cb9-4d76-9ea6-59b720f8b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 2021-03 data\n",
    "fhv_data = spark\\\n",
    "    .read\\\n",
    "    .csv('/home/felipe/repos/tcc/nyc_data/csv/2021/fhv_tripdata_2021-03.csv', header=True)\n",
    "fhvhv_data = spark\\\n",
    "    .read\\\n",
    "    .csv('/home/felipe/repos/tcc/nyc_data/csv/2021/fhvhv_tripdata_2021-03.csv', header=True)\n",
    "\n",
    "# load taxi zones\n",
    "taxi_zones = spark\\\n",
    "    .read\\\n",
    "    .csv('/home/felipe/repos/tcc/nyc_data/csv/taxi_zone_lookup.csv', header=True)\n",
    "\n",
    "# load app lookup\n",
    "apps_lookup = spark\\\n",
    "    .read\\\n",
    "    .csv('/home/felipe/repos/tcc/nyc_data/csv/hvfhs_licenses.csv', header=True)\n",
    "\n",
    "# load NYC shape file to geopandas\n",
    "gdf = geopandas.read_file('/home/felipe/repos/tcc/nyc_data/shapes/taxi_zones/taxi_zones.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b71a2d8-f807-41d9-a724-470ecb401f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv 1301452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv 14227393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get mar data count -> 1,908,099 + 21,734,767\n",
    "print('fhv', fhv_data.count())\n",
    "print('fhvhv', fhvhv_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fab1c5e-679f-47f2-a142-9c05920317ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter off null PU and DO location IDs\n",
    "fhv_data.createOrReplaceTempView(\"FHV_DATA_TEMP_VIEW\")\n",
    "fhv_data = spark.sql(\"SELECT * FROM FHV_DATA_TEMP_VIEW WHERE PULocationID IS NOT NULL AND DOLocationID IS NOT NULL\")\n",
    "\n",
    "fhvhv_data.createOrReplaceTempView(\"FHVHV_DATA_TEMP_VIEW\")\n",
    "fhvhv_data = spark.sql(\"SELECT * FROM FHVHV_DATA_TEMP_VIEW WHERE PULocationID IS NOT NULL AND DOLocationID IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8088a2c4-d391-48ea-a3a1-9f99ab707071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv 199574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=================================================>      (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv 14227393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get apr data count after filtering -> 1,908,099 + 21,734,767\n",
    "print('fhv', fhv_data.count())\n",
    "print('fhvhv', fhvhv_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f4649a-20b9-4b8f-98f5-0f8d45926481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv 189130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv 13766598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# convert PU and DO location ID cols to int and filter off unknown locations\n",
    "fhv_data = fhv_data\\\n",
    "    .withColumn(\"PULocationID\", fhv_data.PULocationID.cast('int'))\\\n",
    "    .withColumn(\"DOLocationID\", fhv_data.DOLocationID.cast('int'))\n",
    "fhv_data = fhv_data.where(\"PULocationID < 264 AND DOLocationID < 264\")\n",
    "\n",
    "fhvhv_data = fhvhv_data\\\n",
    "    .withColumn(\"PULocationID\", fhvhv_data.PULocationID.cast('int'))\\\n",
    "    .withColumn(\"DOLocationID\", fhvhv_data.DOLocationID.cast('int'))\n",
    "fhvhv_data = fhvhv_data.where(\"PULocationID < 264 AND DOLocationID < 264\")\n",
    "\n",
    "# count how many trips did not depart from or arrive to unknown zones -> 237,815 + 21,059,243\n",
    "print('fhv', fhv_data.count())\n",
    "print('fhvhv', fhvhv_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61157073-9562-4b26-b615-922cb5f37aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv 189130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv 13766598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# remove rows where PU and DO cols are 0\n",
    "fhv_data.createOrReplaceTempView(\"FHV_DATA_TEMP_VIEW\")\n",
    "fhv_data = spark.sql(\"SELECT * FROM FHV_DATA_TEMP_VIEW WHERE PULocationID <> 0 AND DOLocationID <> 0\")\n",
    "\n",
    "fhvhv_data.createOrReplaceTempView(\"FHVHV_DATA_TEMP_VIEW\")\n",
    "fhvhv_data = spark.sql(\"SELECT * FROM FHVHV_DATA_TEMP_VIEW WHERE PULocationID <> 0 AND DOLocationID <> 0\")\n",
    "\n",
    "# count how many trips PU and DO locations are 0 -> 237,815 + 21,059,243\n",
    "print('fhv', fhv_data.count())\n",
    "print('fhvhv', fhvhv_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d97b125-3a76-47e6-8c7c-2469b3805692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:47:40 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "21/11/24 13:47:42 ERROR FileOutputCommitter: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/top_ods.csv/_temporary/0\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write top_ods to file or file already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:47:42 ERROR Executor: Exception in task 0.0 in stage 70.0 (TID 205)\n",
      "java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/top_ods.csv/_temporary/0/_temporary/attempt_202111241347425623158701709124234_0070_m_000000_205 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/24 13:47:42 WARN TaskSetManager: Lost task 0.0 in stage 70.0 (TID 205) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/top_ods.csv/_temporary/0/_temporary/attempt_202111241347425623158701709124234_0070_m_000000_205 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/24 13:47:42 ERROR TaskSetManager: Task 0 in stage 70.0 failed 1 times; aborting job\n",
      "21/11/24 13:47:42 ERROR FileFormatWriter: Aborting job 82ae3cab-d0f5-4959-97ca-9d3a8717c03f.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 70.0 failed 1 times, most recent failure: Lost task 0.0 in stage 70.0 (TID 205) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/top_ods.csv/_temporary/0/_temporary/attempt_202111241347425623158701709124234_0070_m_000000_205 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/top_ods.csv/_temporary/0/_temporary/attempt_202111241347425623158701709124234_0070_m_000000_205 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# OD matrix\n",
    "od_size = 264 # 263 + 1 to account for 0-index in list\n",
    "od_data = [[0 for x in range(od_size)] for y in range(od_size)]\n",
    "od_cols = [str(x) for x in range(od_size)]\n",
    "\n",
    "# fill feb OD matrix dataframe\n",
    "fhv_data_collect = fhv_data.toLocalIterator()\n",
    "for fhv_row in fhv_data_collect:\n",
    "    origin = fhv_row.PULocationID\n",
    "    destination = fhv_row.DOLocationID\n",
    "    od_data[origin][destination] += 1\n",
    "    \n",
    "fhvhv_data_collect = fhvhv_data.toLocalIterator()\n",
    "for fhvhv_row in fhvhv_data_collect:\n",
    "    origin = fhvhv_row.PULocationID\n",
    "    destination = fhvhv_row.DOLocationID\n",
    "    od_data[origin][destination] += 1\n",
    "    \n",
    "# create OD dataframe from OD matrix\n",
    "od_dataframe = spark.createDataFrame(data=od_data,schema=od_cols)\n",
    "\n",
    "# create and populate list of max trips from to location\n",
    "od_dataframe_collect = od_dataframe.toLocalIterator()\n",
    "origin = 0\n",
    "od_greatest_values = []\n",
    "\n",
    "for row in od_dataframe_collect:\n",
    "    max_val = max(list(row))\n",
    "    destination = row.index(max_val)\n",
    "    od_greatest_values.append((origin, destination, max_val))\n",
    "    origin += 1\n",
    "\n",
    "# create dataframe from od_greatest_values list\n",
    "od_gr_df_cols = [\"PULocationID\", \"DOLocationID\", \"TripQty\"]\n",
    "od_gr_df = spark.createDataFrame(data=od_greatest_values, schema=od_gr_df_cols)\n",
    "\n",
    "# order by TripQty to find find the top destinations\n",
    "od_gr_df = od_gr_df.orderBy(col(\"TripQty\").desc())\n",
    "# od_gr_df.show(10)\n",
    "\n",
    "# extract may top OD data\n",
    "top_ods = od_gr_df\\\n",
    "    .join(taxi_zones,od_gr_df.PULocationID == taxi_zones.LocationID, \"inner\")\\\n",
    "    .drop(\"Borough\", \"service_zone\")\n",
    "\n",
    "# save may top ODs to file\n",
    "try:\n",
    "    top_ods\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/home/felipe/repos/tcc/nyc_data/csv/2021/03/top_ods.csv\")\n",
    "except:\n",
    "    print(\"Could not write top_ods to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6017cddc-fe82-4e11-8a42-2751798c110e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:35 ERROR FileOutputCommitter: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv/_temporary/0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+------+------+\n",
      "|day of week|morning|   day|  noon| night|\n",
      "+-----------+-------+------+------+------+\n",
      "|        mon| 172818|581685|635380|541877|\n",
      "|        tue| 148133|595497|693124|623861|\n",
      "|        wed| 165628|609250|734324|704127|\n",
      "|        thu| 139462|504042|615269|582879|\n",
      "|        fri| 158302|511186|636195|738934|\n",
      "|        sat| 284148|393240|683421|777141|\n",
      "|        sun| 314293|323676|562862|524974|\n",
      "+-----------+-------+------+------+------+\n",
      "\n",
      "Could not write trip_dow_time to file or file already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:35 ERROR Executor: Exception in task 0.0 in stage 107.0 (TID 270)\n",
      "java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv/_temporary/0/_temporary/attempt_202111241349354669540383450003709_0107_m_000000_270 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/24 13:49:35 WARN TaskSetManager: Lost task 0.0 in stage 107.0 (TID 270) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv/_temporary/0/_temporary/attempt_202111241349354669540383450003709_0107_m_000000_270 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/24 13:49:35 ERROR TaskSetManager: Task 0 in stage 107.0 failed 1 times; aborting job\n",
      "21/11/24 13:49:35 ERROR FileFormatWriter: Aborting job 893095df-5042-4dd2-a8b1-1446e3657574.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 107.0 failed 1 times, most recent failure: Lost task 0.0 in stage 107.0 (TID 270) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv/_temporary/0/_temporary/attempt_202111241349354669540383450003709_0107_m_000000_270 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv/_temporary/0/_temporary/attempt_202111241349354669540383450003709_0107_m_000000_270 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# set up helper lists for trip division by time of day\n",
    "fhv_pickup_times = fhv_data.select(\"pickup_datetime\")\n",
    "fhv_pickup_times = fhv_pickup_times.withColumn(\"pickup_datetime\",to_timestamp(\"pickup_datetime\"))\n",
    "\n",
    "# print(\"!!!!! FHV !!!!!\")\n",
    "# fhv_pickup_times.printSchema()\n",
    "# fhv_pickup_times.show(5)\n",
    "\n",
    "fhvhv_pickup_times = fhvhv_data.select(\"pickup_datetime\")\n",
    "fhvhv_pickup_times = fhvhv_pickup_times.withColumn(\"pickup_datetime\",to_timestamp(\"pickup_datetime\"))\n",
    "\n",
    "# print(\"!!!!! FHVHV !!!!!\")\n",
    "# fhvhv_pickup_times.printSchema()\n",
    "# fhvhv_pickup_times.show(5)\n",
    "\n",
    "# count how many trips per day period\n",
    "# morning: 0:00 to 5:59\n",
    "# day: 6:00 to 11:59\n",
    "# noon: 12:00 to 17:59\n",
    "# night: 18:00 to 23:59\n",
    "# weekday is 0-index starting monday (0), then tuesday (1), etc.\n",
    "\n",
    "MORNING=1\n",
    "DAY=2\n",
    "NOON=3\n",
    "NIGHT=4\n",
    "trip_groups_schema = ['day of week', 'morning', 'day', 'noon', 'night']\n",
    "trip_groups = [['mon', 0, 0, 0, 0],\\\n",
    "               ['tue', 0, 0, 0, 0],\\\n",
    "               ['wed', 0, 0, 0, 0],\\\n",
    "               ['thu', 0, 0, 0, 0],\\\n",
    "               ['fri', 0, 0, 0, 0],\\\n",
    "               ['sat', 0, 0, 0, 0],\\\n",
    "               ['sun', 0, 0, 0, 0]]\n",
    "\n",
    "fhv_pickup_times_collect = fhv_pickup_times.toLocalIterator()\n",
    "\n",
    "for row in fhv_pickup_times_collect:\n",
    "    trip_weekday = row.pickup_datetime.weekday()\n",
    "    trip_hour = row.pickup_datetime.hour\n",
    "    if 0 <= trip_hour <= 5:\n",
    "        trip_groups[trip_weekday][MORNING] += 1\n",
    "    elif 6 <= trip_hour <= 11:\n",
    "        trip_groups[trip_weekday][DAY] += 1\n",
    "    elif 12 <= trip_hour <= 17:\n",
    "        trip_groups[trip_weekday][NOON] += 1\n",
    "    elif 18 <= trip_hour <= 23:\n",
    "        trip_groups[trip_weekday][NIGHT] += 1\n",
    "\n",
    "fhvhv_pickup_times_collect = fhvhv_pickup_times.toLocalIterator()\n",
    "\n",
    "for row in fhvhv_pickup_times_collect:\n",
    "    trip_weekday = row.pickup_datetime.weekday()\n",
    "    trip_hour = row.pickup_datetime.hour\n",
    "    if 0 <= trip_hour <= 5:\n",
    "        trip_groups[trip_weekday][MORNING] += 1\n",
    "    elif 6 <= trip_hour <= 11:\n",
    "        trip_groups[trip_weekday][DAY] += 1\n",
    "    elif 12 <= trip_hour <= 17:\n",
    "        trip_groups[trip_weekday][NOON] += 1\n",
    "    elif 18 <= trip_hour <= 23:\n",
    "        trip_groups[trip_weekday][NIGHT] += 1\n",
    "        \n",
    "# create DF from trip dow group matrix\n",
    "trip_dow_df = spark.createDataFrame(data=trip_groups, schema=trip_groups_schema)\n",
    "\n",
    "# show trip_dow_df\n",
    "trip_dow_df.show()\n",
    "\n",
    "# write trip_dow_df to file\n",
    "try:\n",
    "    trip_dow_df\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trip_dow_time.csv\")\n",
    "except:\n",
    "    print(\"Could not write trip_dow_time to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0cc9df-0a98-48a2-8879-d5980d7c6c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared fhv trips 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:>                                                      (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared fhvhv trips 5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get trips that were shared\n",
    "fhv_data.createOrReplaceTempView(\"FHV_DATA_TEMP_VIEW\")\n",
    "fhv_shared_trips = spark.sql(\"SELECT * FROM FHV_DATA_TEMP_VIEW WHERE SR_Flag IS NOT NULL\")\n",
    "\n",
    "fhvhv_data.createOrReplaceTempView(\"FHVHV_DATA_TEMP_VIEW\")\n",
    "fhvhv_shared_trips = spark.sql(\"SELECT * FROM FHVHV_DATA_TEMP_VIEW WHERE SR_Flag IS NOT NULL\")\n",
    "\n",
    "# count how many trips were shared -> 0 + 3,826,284\n",
    "\n",
    "# As per the documentation, there are trips that were flagged as shareable.\n",
    "# however, this does not mean that it was, since Lyft flags as shared even though\n",
    "# the original rider wasnt matched with someone else.\n",
    "# For the purposes of this study, we will analyze the users intent to share.\n",
    "\n",
    "print('shared fhv trips', fhv_shared_trips.count())\n",
    "print('shared fhvhv trips', fhvhv_shared_trips.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d77566cd-f3e1-467e-a4ed-8a27b3afac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:38 ERROR FileOutputCommitter: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv/_temporary/0\n",
      "21/11/24 13:49:43 ERROR Executor: Exception in task 0.0 in stage 117.0 (TID 937)\n",
      "java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv/_temporary/0/_temporary/attempt_202111241349425603907914610856338_0117_m_000000_937 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/24 13:49:43 WARN TaskSetManager: Lost task 0.0 in stage 117.0 (TID 937) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv/_temporary/0/_temporary/attempt_202111241349425603907914610856338_0117_m_000000_937 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/24 13:49:43 ERROR TaskSetManager: Task 0 in stage 117.0 failed 1 times; aborting job\n",
      "21/11/24 13:49:43 ERROR FileFormatWriter: Aborting job 0e37475c-e44b-42a5-9ea9-dc1644c7493e.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 117.0 failed 1 times, most recent failure: Lost task 0.0 in stage 117.0 (TID 937) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv/_temporary/0/_temporary/attempt_202111241349425603907914610856338_0117_m_000000_937 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv/_temporary/0/_temporary/attempt_202111241349425603907914610856338_0117_m_000000_937 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "21/11/24 13:49:43 ERROR FileOutputCommitter: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv/_temporary/0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write trips_by_pu to file or file already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write trips_by_do to file or file already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:47 ERROR Executor: Exception in task 0.0 in stage 123.0 (TID 1570)\n",
      "java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv/_temporary/0/_temporary/attempt_20211124134946520701320263970634_0123_m_000000_1570 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/24 13:49:47 WARN TaskSetManager: Lost task 0.0 in stage 123.0 (TID 1570) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv/_temporary/0/_temporary/attempt_20211124134946520701320263970634_0123_m_000000_1570 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/24 13:49:47 ERROR TaskSetManager: Task 0 in stage 123.0 failed 1 times; aborting job\n",
      "21/11/24 13:49:47 ERROR FileFormatWriter: Aborting job 8e70e2b1-f59e-4a31-8d9c-10b577b21716.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 123.0 failed 1 times, most recent failure: Lost task 0.0 in stage 123.0 (TID 1570) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv/_temporary/0/_temporary/attempt_20211124134946520701320263970634_0123_m_000000_1570 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv/_temporary/0/_temporary/attempt_20211124134946520701320263970634_0123_m_000000_1570 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# count top departure, arrival zones and write to file\n",
    "pu_data = fhv_data\\\n",
    "    .select(\"PULocationID\")\\\n",
    "    .union(fhvhv_data\\\n",
    "           .select(\"PULocationID\"))\n",
    "\n",
    "trips_by_pu = pu_data\\\n",
    "    .groupBy(\"PULocationID\")\\\n",
    "    .count()\\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "try:\n",
    "    trips_by_pu\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_pu.csv\")\n",
    "except:\n",
    "    print(\"Could not write trips_by_pu to file or file already exists\")\n",
    "\n",
    "do_data = fhv_data\\\n",
    "    .select(\"DOLocationID\")\\\n",
    "    .union(fhvhv_data\\\n",
    "           .select(\"DOLocationID\"))\n",
    "\n",
    "trips_by_do = do_data\\\n",
    "    .groupBy(\"DOLocationID\")\\\n",
    "    .count()\\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "try:\n",
    "    trips_by_do\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_by_do.csv\")\n",
    "except:\n",
    "    print(\"Could not write trips_by_do to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a21104e7-c319-4fca-8ec1-c31e0daca795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:49 ERROR FileOutputCommitter: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv/_temporary/0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|company_name|count|\n",
      "+------------+-----+\n",
      "|         Via| 5041|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write trips_shared_by_app to file or file already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:49:52 ERROR Executor: Exception in task 0.0 in stage 133.0 (TID 2206)\n",
      "java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv/_temporary/0/_temporary/attempt_202111241349517043108014714883244_0133_m_000000_2206 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/24 13:49:52 WARN TaskSetManager: Lost task 0.0 in stage 133.0 (TID 2206) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv/_temporary/0/_temporary/attempt_202111241349517043108014714883244_0133_m_000000_2206 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/24 13:49:52 ERROR TaskSetManager: Task 0 in stage 133.0 failed 1 times; aborting job\n",
      "21/11/24 13:49:52 ERROR FileFormatWriter: Aborting job 8eabaa98-6333-4195-98c2-29743df873dd.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 133.0 failed 1 times, most recent failure: Lost task 0.0 in stage 133.0 (TID 2206) (172.30.165.94 executor driver): java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv/_temporary/0/_temporary/attempt_202111241349517043108014714883244_0133_m_000000_2206 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: Mkdirs failed to create file:/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv/_temporary/0/_temporary/attempt_202111241349517043108014714883244_0133_m_000000_2206 (exists=false, cwd=file:/home/felipe/repos/tcc/nyc_data/notebooks/2021)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)\n",
      "\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n",
      "\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n",
      "\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# get what app is most used to share rides\n",
    "shared_trips = fhvhv_data.where(\"SR_Flag IS NOT NULL\")\n",
    "shared_trips = shared_trips.drop(\"dispatching_base_num\")\n",
    "shared_trips = shared_trips\\\n",
    "    .join(apps_lookup,\n",
    "          shared_trips.hvfhs_license_num == apps_lookup.hvfhs_license_num)\\\n",
    "    .drop(\"hvfhs_license_num\")\n",
    "\n",
    "shared_trips = shared_trips\\\n",
    "    .groupBy(\"company_name\")\\\n",
    "    .count()\\\n",
    "    .orderBy(\"count\")\n",
    "\n",
    "shared_trips.show()\n",
    "\n",
    "# write shared_trips to file\n",
    "try:\n",
    "    shared_trips\\\n",
    "        .repartition(1)\\\n",
    "        .write.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(\"/media/felipe/Files/repos/tcc/nyc_data/csv/2021/03/trips_shared_by_app.csv\")\n",
    "except:\n",
    "    print(\"Could not write trips_shared_by_app to file or file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0767c289-4ee1-4b61-80f3-e7e2241f069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# find missing lines from pu and do lists\n",
    "all_location_ids = taxi_zones\\\n",
    "    .select(\"LocationID\")\\\n",
    "    .where(\"LocationID < 264\")\\\n",
    "    .withColumn(\"LocationID\", taxi_zones.LocationID.cast(\"int\"))\n",
    "all_location_ids = np.array(all_location_ids.collect()).reshape(-1)\n",
    "\n",
    "location_ids_pu = np.array(trips_by_pu.select(\"PULocationID\").collect()).reshape(-1)\n",
    "location_ids_do = np.array(trips_by_do.select(\"DOLocationID\").collect()).reshape(-1)\n",
    "\n",
    "pu_schema = [\"PULocationID\", \"count\"]\n",
    "do_schema = [\"DOLocationID\", \"count\"]\n",
    "missing_locations_pu = []\n",
    "missing_locations_do = []\n",
    "\n",
    "for location_id in np.nditer(all_location_ids):\n",
    "    if location_id not in location_ids_pu:\n",
    "        missing_locations_pu.append((location_id.flatten().item(0),0))\n",
    "    if location_id not in location_ids_do:\n",
    "        missing_locations_do.append((location_id.flatten().item(0),0))\n",
    "\n",
    "missing_pu_data = spark.createDataFrame(data=missing_locations_pu,schema=pu_schema)\n",
    "trips_by_pu = trips_by_pu\\\n",
    "    .union(missing_pu_data)\\\n",
    "    .orderBy(\"PULocationID\")\n",
    "trips_by_pu_count = np.array(trips_by_pu.select(\"count\").collect()).reshape(-1)\n",
    "\n",
    "missing_do_data = spark.createDataFrame(data=missing_locations_do,schema=do_schema)\n",
    "trips_by_do = trips_by_do\\\n",
    "    .union(missing_do_data)\\\n",
    "    .orderBy(\"DOLocationID\")\n",
    "trips_by_do_count = np.array(trips_by_do.select(\"count\").collect()).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece3fd9b-8e99-4867-b050-141329bb2eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get df with company name instead of license number\n",
    "fhvhv_data_cmp_name = fhvhv_data\\\n",
    "    .join(apps_lookup,\n",
    "          fhvhv_data.hvfhs_license_num == apps_lookup.hvfhs_license_num)\\\n",
    "    .withColumn(\"PULocationID\", fhvhv_data.PULocationID.cast(\"int\"))\\\n",
    "    .withColumn(\"DOLocationID\", fhvhv_data.DOLocationID.cast(\"int\"))\\\n",
    "    .drop(\"hvfhs_license_num\", \"dispatching_base_num\")\n",
    "\n",
    "fhvhv_data_cmp_name = fhvhv_data_cmp_name\\\n",
    "    .groupBy(\"PULocationID\", \"company_name\", \"company_color\")\\\n",
    "    .count()\\\n",
    "    .orderBy(\"PULocationID\")\n",
    "\n",
    "fhvhv_data_cmp_name.createOrReplaceTempView(\"TMP_VIEW\")\n",
    "\n",
    "query = \"SELECT PULocationID, company_name, company_color, count FROM (SELECT *, MAX(count) OVER (PARTITION BY PULocationID) AS maxCount FROM TMP_VIEW) M WHERE count = maxCount\"\n",
    "\n",
    "fhvhv_data_cmp_name = spark.sql(query)\n",
    "\n",
    "# fhvhv_data_cmp_name.show(110)\n",
    "\n",
    "# fixture specific for may\n",
    "# fhvhv_data_cmp_name = fhvhv_data_cmp_name\\\n",
    "#     .withColumn(\"PULocationID\", when((col(\"PULocationID\") == 105) & (col(\"company_name\") == 'Lyft'), 104)\\\n",
    "#                .otherwise(col(\"PULocationID\")))\n",
    "# fhvhv_data_cmp_name = fhvhv_data_cmp_name\\\n",
    "#     .withColumn(\"PULocationID\", when((col(\"PULocationID\") == 105) & (col(\"company_name\") == 'Juno'), 103)\\\n",
    "#                .otherwise(col(\"PULocationID\")))\n",
    "# fixture specific for may\n",
    "\n",
    "# find missing PULocationID in fhvhv_data_cmp_name\n",
    "pu_schema = [\"PULocationID\", \"company_name\", \"company_color\", \"count\"]\n",
    "missing_locations_pu = []\n",
    "\n",
    "location_ids_pu = np.array(fhvhv_data_cmp_name.select(\"PULocationID\").collect()).reshape(-1)\n",
    "\n",
    "for location_id in np.nditer(all_location_ids):\n",
    "    if location_id not in location_ids_pu:\n",
    "        missing_locations_pu.append((location_id.flatten().item(0),'No data','#808080',np.nan))\n",
    "\n",
    "missing_pu_data = spark.createDataFrame(data=missing_locations_pu,schema=pu_schema)\n",
    "fhvhv_data_cmp_name = fhvhv_data_cmp_name\\\n",
    "    .union(missing_pu_data)\\\n",
    "    .orderBy(\"PULocationID\")\n",
    "\n",
    "fhvhv_data_cmp_color = np.array(fhvhv_data_cmp_name.select('company_color').collect()).reshape(-1)\n",
    "fhvhv_data_cmp_name_name = np.array(fhvhv_data_cmp_name.select('company_name').collect()).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c978f81-cd35-4efa-80c2-3814a02b52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cols to gdf\n",
    "gdf['Trips_by_PULocationID'] = trips_by_pu_count\n",
    "gdf['Trips_by_DOLocationID'] = trips_by_do_count\n",
    "gdf['Top_Company_Color'] = fhvhv_data_cmp_color\n",
    "gdf['Top_Company_Name'] = fhvhv_data_cmp_name_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db08a829-c5bf-4722-b379-a1b0d376d619",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_PU.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10884/435245011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m          legend_kwds={'label': \"Pickups by Zone\", 'orientation': \"vertical\"})\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_PU.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3013\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3015\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2259\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2262\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 **kwargs)\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_jpg\u001b[0;34m(self, filename_or_obj, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# Drop alpha channel now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         return (Image.fromarray(np.asarray(self.buffer_rgba())[..., :3])\n\u001b[0;32m--> 585\u001b[0;31m                 .save(filename_or_obj, format='jpeg', **pil_kwargs))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0mprint_jpeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_jpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_PU.jpg'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot PU trip heatmap\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.title('NYC, Mar 2021')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "gdf.plot(cmap='coolwarm',\n",
    "         column='Trips_by_PULocationID',\n",
    "         ax=ax,\n",
    "         legend=True,\n",
    "         legend_kwds={'label': \"Pickups by Zone\", 'orientation': \"vertical\"})\n",
    "plt.savefig('/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_PU.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42c563-ab44-4ca2-8fd7-cb938bac3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot DO trip heatmap\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.title('NYC, Mar 2021')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "gdf.plot(cmap='coolwarm',\n",
    "         column='Trips_by_DOLocationID',\n",
    "         ax=ax,\n",
    "         legend=True,\n",
    "         legend_kwds={'label': \"Dropoffs by Zone\", 'orientation': \"vertical\"})\n",
    "plt.savefig('/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_DO.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbba7b-9bfe-413b-aeda-ec9a18507a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top companies\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.title('Most used app by NYC zone, Mar 2021')\n",
    "uber_patch = mpatches.Patch(color='#000000', label='Uber')\n",
    "lyft_patch = mpatches.Patch(color='#E867CB', label='Lyft')\n",
    "via_patch = mpatches.Patch(color='#2AB6E6', label='Via')\n",
    "juno_patch = mpatches.Patch(color='#29509F', label='Juno')\n",
    "no_data_patch = mpatches.Patch(color='#808080', label='No data')\n",
    "plt.legend(handles=[uber_patch,lyft_patch,via_patch,juno_patch], loc='upper left')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "gdf.plot(color=gdf['Top_Company_Color'],\n",
    "         ax=ax,\n",
    "         legend=True)\n",
    "plt.savefig('/media/felipe/Files/repos/tcc/nyc_data/imgs/2021-03_App.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbcc06-0466-42d0-88f5-b98200a927dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

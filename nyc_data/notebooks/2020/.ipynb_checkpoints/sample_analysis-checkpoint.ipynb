{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08a3bdc-6b63-486f-b7f2-0c1cf3e95b77",
   "metadata": {},
   "source": [
    "# Analysis - 2020\n",
    "Given Uber ride information and COVID information from NYC, what what is the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31366b3d-104b-4652-8186-5d543a6fdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('/home/felipe/repos/tcc/nyc_data/csv/2020_preprocessed_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8d6af0-463e-4da4-a104-42df2f7945f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['SR_Flag']\n",
    "X = dataset.drop('SR_Flag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76408bbb-0776-4e24-9a28-5eec4cd129fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "trip_max_idx = X['trip_duration'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206436b7-1386-4508-a130-aca7299d22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/felipe/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of Series.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X.drop(X.index[trip_max_idx], 0, inplace=True)\n",
    "y.drop(y.index[trip_max_idx], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a447249-d37a-40ff-b199-b93333372d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d52a6a-cc12-4b8a-85e2-116a8f9a9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      trip_duration <= 5\n",
    "#  5 < trip_duration <= 10\n",
    "# 10 < trip_duration <= 15\n",
    "# 15 < trip_duration <= 20\n",
    "# 20 < trip_duration <= 30\n",
    "# 30 < trip_duration <= 45\n",
    "# 45 < trip_duration <= 60\n",
    "# 60 < trip_duration\n",
    "X['trip_duration'] = pd.qcut(X['trip_duration'], 8, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6898ff-db26-49f3-9107-38cbe9efb0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8cb063-3e25-4537-964b-480fbcdb83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "k_folds = range(2,12)\n",
    "\n",
    "decision_tree_scores_cv = cross_validate(decision_tree_clf, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                                  'precision': precision_scorer,\n",
    "                                                                                  'recall': recall_scorer,\n",
    "                                                                                  'f1': f1_scorer,\n",
    "                                                                                  'rmse': rmse_scorer})\n",
    "decision_tree_accuracy_scores = decision_tree_scores_cv['test_accuracy'].tolist()\n",
    "decision_tree_precision_scores = decision_tree_scores_cv['test_precision'].tolist()\n",
    "decision_tree_recall_scores = decision_tree_scores_cv['test_recall'].tolist()\n",
    "decision_tree_f1_scores = decision_tree_scores_cv['test_f1'].tolist()\n",
    "decision_tree_rmse_scores = decision_tree_scores_cv['test_rmse'].tolist()\n",
    "\n",
    "decision_tree_scores = {'accuracy': decision_tree_accuracy_scores,\n",
    "                        'precision': decision_tree_precision_scores,\n",
    "                        'recall': decision_tree_recall_scores,\n",
    "                        'f1': decision_tree_f1_scores,\n",
    "                        'rmse': decision_tree_rmse_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a939c204-0f07-4ad0-ab35-0976cc5b2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "depths = range(1,11)\n",
    "random_forest_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    accuracy_scorer = make_scorer(accuracy_score)\n",
    "    precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "    recall_scorer = make_scorer(recall_score)\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "    rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "    \n",
    "    random_forest_clf = RandomForestClassifier(max_depth=depth, bootstrap=False)\n",
    "    scores = cross_validate(random_forest_clf, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                     'precision': precision_scorer,\n",
    "                                                                     'recall': recall_scorer,\n",
    "                                                                     'f1': f1_scorer,\n",
    "                                                                     'rmse': rmse_scorer})\n",
    "    random_forest_acc = scores['test_accuracy'].tolist()\n",
    "    random_forest_prec = scores['test_precision'].tolist()\n",
    "    random_forest_recall = scores['test_recall'].tolist()\n",
    "    random_forest_f1 = scores['test_f1'].tolist()\n",
    "    random_forest_rmse = scores['test_rmse'].tolist()\n",
    "    \n",
    "    random_forest_scores.append({'depth': depth,\n",
    "                                 'accuracy': random_forest_acc,\n",
    "                                 'precision': random_forest_prec,\n",
    "                                 'recall': random_forest_recall,\n",
    "                                 'f1': random_forest_f1,\n",
    "                                 'rmse': random_forest_rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1eb508-1349-4e8b-86e5-206f033ffcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_values = range(1,6)\n",
    "knn_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    accuracy_scorer = make_scorer(accuracy_score)\n",
    "    precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "    recall_scorer = make_scorer(recall_score)\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "    rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_validate(knn_clf, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                       'precision': precision_scorer,\n",
    "                                                       'recall': recall_scorer,\n",
    "                                                       'f1': f1_scorer,\n",
    "                                                       'rmse': rmse_scorer})\n",
    "    knn_acc = scores['test_accuracy'].tolist()\n",
    "    knn_prec = scores['test_precision'].tolist()\n",
    "    knn_recall = scores['test_recall'].tolist()\n",
    "    knn_f1 = scores['test_f1'].tolist()\n",
    "    knn_rmse = scores['test_rmse'].tolist()\n",
    "    \n",
    "    knn_scores.append({'k': k,\n",
    "                       'accuracy': knn_acc,\n",
    "                       'precision': knn_prec,\n",
    "                       'recall': knn_recall,\n",
    "                       'f1': knn_f1,\n",
    "                       'rmse': knn_rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f373bac-a3a1-44d8-987d-0818d4d351a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_values = range(1,6)\n",
    "kmeans_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    accuracy_scorer = make_scorer(accuracy_score)\n",
    "    precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "    recall_scorer = make_scorer(recall_score)\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "    rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "    kmeans_recall_scorer = make_scorer(recall_score, zero_division=1, average='weighted')\n",
    "    kmeans_f1_scorer = make_scorer(f1_score, zero_division=1, average='weighted')\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    acc_scores = cross_val_score(kmeans, X, y, cv=10, scoring='accuracy')\n",
    "    prec_scores = cross_val_score(kmeans, X, y, cv=10, scoring=precision_scorer)\n",
    "    recall_scores = cross_val_score(kmeans, X, y, cv=10, scoring=kmeans_recall_scorer)\n",
    "    f1_scores = cross_val_score(kmeans, X, y, cv=10, scoring=kmeans_f1_scorer)\n",
    "    rmse_scores = cross_val_score(kmeans, X, y, cv=10, scoring=rmse_scorer)\n",
    "    \n",
    "    kmeans_scores.append({'k': k,\n",
    "                          'accuracy': acc_scores.tolist(),\n",
    "                          'precision': prec_scores.tolist(),\n",
    "                          'recall': recall_scores.tolist(),\n",
    "                          'f1': f1_scores.tolist(),\n",
    "                          'rmse': rmse_scores.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6c5b17-2603-47b2-af96-7141c46a44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "mlp_classifier = MLPClassifier(solver='adam', hidden_layer_sizes=(100, 5))\n",
    "mlp_scores = cross_validate(mlp_classifier, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                  'precision': precision_scorer,\n",
    "                                                                  'recall': recall_scorer,\n",
    "                                                                  'f1': f1_scorer,\n",
    "                                                                  'rmse': rmse_scorer})\n",
    "mlp_acc = mlp_scores['test_accuracy'].tolist()\n",
    "mlp_prec = mlp_scores['test_precision'].tolist()\n",
    "mlp_recall = mlp_scores['test_recall'].tolist()\n",
    "mlp_f1 = mlp_scores['test_f1'].tolist()\n",
    "mlp_rmse = mlp_scores['test_rmse'].tolist()\n",
    "\n",
    "mlp_scores = {'accuracy': mlp_acc,\n",
    "              'precision': mlp_prec,\n",
    "              'recall': mlp_recall,\n",
    "              'f1': mlp_f1,\n",
    "              'rmse': mlp_rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df8aad11-b788-4cab-a062-2842ce2cf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_scores = cross_validate(gnb_classifier, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                  'precision': precision_scorer,\n",
    "                                                                  'recall': recall_scorer,\n",
    "                                                                  'f1': f1_scorer,\n",
    "                                                                  'rmse': rmse_scorer})\n",
    "gnb_acc = gnb_scores['test_accuracy'].tolist()\n",
    "gnb_prec = gnb_scores['test_precision'].tolist()\n",
    "gnb_recall = gnb_scores['test_recall'].tolist()\n",
    "gnb_f1 = gnb_scores['test_f1'].tolist()\n",
    "gnb_rmse = gnb_scores['test_rmse'].tolist()\n",
    "\n",
    "gnb_scores = {'accuracy': gnb_acc,\n",
    "              'precision': gnb_prec,\n",
    "              'recall': gnb_recall,\n",
    "              'f1': gnb_f1,\n",
    "              'rmse': gnb_rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf22f87-3d11-4c1e-84a0-b8f0ccb2fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "cnb_classifier = ComplementNB()\n",
    "cnb_scores = cross_validate(cnb_classifier, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                  'precision': precision_scorer,\n",
    "                                                                  'recall': recall_scorer,\n",
    "                                                                  'f1': f1_scorer,\n",
    "                                                                  'rmse': rmse_scorer})\n",
    "cnb_acc = cnb_scores['test_accuracy'].tolist()\n",
    "cnb_prec = cnb_scores['test_precision'].tolist()\n",
    "cnb_recall = cnb_scores['test_recall'].tolist()\n",
    "cnb_f1 = cnb_scores['test_f1'].tolist()\n",
    "cnb_rmse = cnb_scores['test_rmse'].tolist()\n",
    "\n",
    "cnb_scores = {'accuracy': cnb_acc,\n",
    "              'precision': cnb_prec,\n",
    "              'recall': cnb_recall,\n",
    "              'f1': cnb_f1,\n",
    "              'rmse': cnb_rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ad4f3e-0b95-4954-9fb1-2ff27801191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, zero_division=0, average='weighted')\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_scores = cross_validate(mnb_classifier, X, y, cv=10, scoring={'accuracy': accuracy_scorer,\n",
    "                                                                  'precision': precision_scorer,\n",
    "                                                                  'recall': recall_scorer,\n",
    "                                                                  'f1': f1_scorer,\n",
    "                                                                  'rmse': rmse_scorer})\n",
    "mnb_acc = mnb_scores['test_accuracy'].tolist()\n",
    "mnb_prec = mnb_scores['test_precision'].tolist()\n",
    "mnb_recall = mnb_scores['test_recall'].tolist()\n",
    "mnb_f1 = mnb_scores['test_f1'].tolist()\n",
    "mnb_rmse = mnb_scores['test_rmse'].tolist()\n",
    "\n",
    "mnb_scores = {'accuracy': mnb_acc,\n",
    "              'precision': mnb_prec,\n",
    "              'recall': mnb_recall,\n",
    "              'f1': mnb_f1,\n",
    "              'rmse': mnb_rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff3d7994-cfb6-418c-8670-400112f0dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_scores = {'decision_tree': decision_tree_scores,\n",
    "                     'random_forest': random_forest_scores,\n",
    "                     'knn': knn_scores,\n",
    "                     'kmeans': kmeans_scores,\n",
    "                     'mlp': mlp_scores,\n",
    "                     'gnb': gnb_scores,\n",
    "                     'cnb': cnb_scores,\n",
    "                     'mnb': mnb_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf59fdc-10e7-45d4-9c6f-9c11b791c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('2020_scores.json', 'w') as json_2020:\n",
    "    json.dump(supervised_scores, json_2020, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
